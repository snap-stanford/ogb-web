---
title: Node Property Prediction
permalink: /docs/nodeprop/
---

##### The task is to predict properties of single nodes.

### Summary

#### - Datasets

##### **The current datasets are subject to change until the paper is released (expected to be around mid April).**

Scale | Name                              | #Nodes  | #Edges\* | #Task | Split Type        | Task Type   | Metric                  |
|-------------|---------|----------------|----------------------|---------------------|---------------------------|--------------------|
Medium | [ogbn-proteins](#ogbn-proteins) | 132,534  |  39,561,252 | 112       | Species  | Binary classification   | ROC-AUC     |
Medium | [ogbn-products](#ogbn-products) | 2,449,029  | 61,859,140 | 1       | Time      | Multi-class classification | Accuracy |

**Note:** For undirected graphs, the loaded graphs will have the doubled number of edges because we add the bidirectional edges automatically.

#### - Module
We prepare different [data loader](#loader) variants: (1) [Pytorch Geometric one](#pyg) (2) [DGL one](#dgl) and (3) [library-agnostic one](#libagn).
We also prepare a unified [performance evaluator](#eval).

<a name="ogbn-proteins"/>

------

### Dataset `ogbn-proteins` ([Leaderboard](../leader_nodeprop/#ogbn-proteins)):

**Graph:** `ogbn-proteins` is an undirected, weighted, and typed (according to species) graph. Nodes represent proteins, and edges indicate different types of biologically meaningful associations between proteins, e.g., physical interactions, co-expression or homology [1,2]. All edges come with 8-dimensional features, where each dimension represents the strength of a single association type and takes values between 0 and 1 (the larger the value is, the stronger the association is). The proteins come from 8 species. The nodes are attached with the taxonomy ID indicating the species from which the proteins come from.


**Prediction task:** The task is to predict the presence of protein functions in a multi-label binary classification setup, where there are 112 kinds of labels to predict in total.

**Dataset splitting:** We split the protein nodes into training/validation/test sets according to the species from which the proteins come from. This enables the evaluation of the generalization performance of the model *across* different species. 


#### References
[1] Szklarczyk, D., Gable, A.L., Lyon, D., Junge, A., Wyder, S., Huerta-Cepas, J., Simonovic, M., Doncheva, N.T., Morris, J.H., Bork, P. and Jensen, L.J., 2018. STRING v11: proteinâ€“protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Nucleic Acids Research, 47(D1), pp.D607-D613. <br/>
[2] Ashburner, M., Ball, C.A., Blake, J.A., Botstein, D., Butler, H., Cherry, J.M., Davis, A.P., Dolinski, K., Dwight, S.S., Eppig, J.T. and Harris, M.A., 2000. Gene ontology: tool for the unification of biology. Nature Genetics, 25(1), p.25.

<a name="ogbn-products"/>

----------

### Dataset `ogbn-products` ([Leaderboard](../leader_nodeprop/#ogbn-products)):

**Graph:** `ogbn-products` is an undirected and unweighted graph, representing an Amazon product co-purchasing network [1]. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. We follow [2] to process node features and target categories. Specifically, node features are generated by extracting bag-of-words features from the product descriptions followed by a Principal Component Analysis to reduce the dimension to 100.

**Prediction task:** The task is to predict the category of a product in a multi-class classification setup, where the 47 top-level categories are used for target labels.

**Dataset splitting:** We consider a more challenging and realistic dataset splitting that differs from the one used in [2].
Instead of randomly assigning 90% of the nodes for training and 10% of the nodes for testing (without use of a validation set), we use the *sales ranking* (popularity) to split nodes into training/validation/test sets.
Specifically, we sort the products according to their sales ranking and use the top 10% for training, next top 2% for validation, and the rest for testing. This is a more challenging splitting procedure that closely matches the real-world application where labels are first assigned to important nodes in the network and machine learning is subsequently used to make predictions on less important ones.

#### References
[1] http://manikvarma.org/downloads/XC/XMLRepository.html <br/>
[2] Chiang, W. L., Liu, X., Si, S., Li, Y., Bengio, S., & Hsieh, C. J. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. SIGKDD 2019.

<a name="loader"/>

----------

### Data Loader

To load a dataset, replace `d_name` with the dataset name (e.g., `"ogbn-proteins"`).

<a name="pyg"/>

#### Pytorch Geometric Loader

```python
from ogb.nodeproppred import PygNodePropPredDataset

dataset = PygNodePropPredDataset(name = d_name) 
num_tasks = dataset.num_tasks # obtaining the number of prediction tasks in a dataset

splitted_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = splitted_idx["train"], splitted_idx["valid"], splitted_idx["test"]
graph = dataset[0] # pyg graph object
```

<a name="dgl"/>

#### DGL Loader

```python
from ogb.nodeproppred import DglNodePropPredDataset

dataset = NodePropPredDataset(name = d_name)
num_tasks = dataset.num_tasks # obtaining the number of prediction tasks in a dataset

splitted_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = splitted_idx["train"], splitted_idx["valid"], splitted_idx["test"]
graph, label = dataset[0] # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)
```
`{train,valid,test}_idx` are torch tensors of shape `(num_nodes,)`, representing the node indices assigned to training/validation/test sets.
Prediction target in the Pytorch Geometric dataset can be accessed by `graph.y`, which is a torch tensor of shape `(num_nodes, num_tasks)`, where the i-th row represents the target labels of i-th node.

<a name="libagn"/>

#### Library-Agnostic Loader
```python
from ogb.nodeproppred import NodePropPredDataset

dataset = NodePropPredDataset(name = d_name)
num_tasks = dataset.num_tasks # obtaining the number of prediction tasks in a dataset

splitted_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = splitted_idx["train"], splitted_idx["valid"], splitted_idx["test"]
graph, label = dataset[0] # graph: library-agnostic graph object
```
The library-agnostic graph object is a dictionary containing the following keys: `edge_index`, `edge_feat`, `node_feat`, and `num_nodes`, which are detailed below.
- `edge_index`: numpy arrays of shape `(2, num_edges)`, where each column represents an edge. The first row and the second row represent the indices of source and target nodes. Undirected edges are represented by bi-directional edges.
- `edge_feat`: numpy arrays of shape `(num_edges, edgefeat_dim)`, where `edgefeat_dim` is the dimensionality of edge features and i-th row represents the feature of i-th edge. This can be `None` if no input edge features are available.
- `node_feat`: numpy arrays of shape `(num_nodes, nodefeat_dim)`, where `nodefeat_dim` is the dimensionality of node features and i-th row represents the feature of i-th node. This can be `None` if no input node features are available.
- `num_nodes`: number of nodes in the graph.

**Node:** Some graph datasets may contain additional meta-information in node or edges such as their time stamps. Although they are not given as default input features, researchers should feel free to exploit these additional information.

<a name="eval"/>

----------


### Performance Evaluator

Evaluators are customized for each dataset.
We require users to pass a pre-specified format to the evaluator.
First, please learn the input and output format specification of the evaluator as follows.

```python
from ogb.nodeproppred import Evaluator

evaluator = Evaluator(name = d_name)
print(evaluator.expected_input_format) 
print(evaluator.expected_output_format) 
```

Then, you can pass the input dictionary (denoted by `input_dict` below) of the specified format, and get the performance of your prediction.

```python
# In most cases, input_dict is
# input_dict = {"y_true": y_true, "y_pred": y_pred}
result_dict = evaluator.eval(input_dict)
```
