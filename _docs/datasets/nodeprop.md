---
title: Node Property Prediction
permalink: /docs/nodeprop/
---

##### The task is to predict properties of single nodes.

### Summary

#### - Datasets

Scale | Name                              | #Nodes  | #Edges\* | #Task | Split Type        | Task Type   | Metric                  |
|-------------|---------|----------------|----------------------|---------------------|---------------------------|--------------------|
Medium | [ogbn-proteins](#ogbn-proteins) | 132,534  |  39,561,252 | 112       | Species  | Binary classification   | ROC-AUC     |
Medium | [ogbn-products](#ogbn-products) | 2,449,029  | 61,859,140 | 1       | Time      | Multi-class classification | Accuracy |


\* Note that for undirected graphs, the loaded graphs will have the doubled number of edges becausewe add the bidirectional edges automatically.

#### - Module
We prepare different [data loader](#loader) variants: (1) [Pytorch Geometric one](#pyg) (2) [DGL one](#dgl) and (3) [library-agnostic one](#libagn).
We also prepare a unified [performance evaluator](#eval).

------

<a name="ogbn-proteins"/>
### Dataset `ogbn-proteins`: ([Leaderboard](../leader_nodeprop/#ogbn-proteins))

**Graph:** `ogbn-proteins` is an undirected, weighted, and typed graph (according to species). Nodes represent proteins, and edges indicate different types of biologically meaningful associations between proteins (e.g., physical interactions, co-expression, homology) [1,2]. 
The edges come with 8-dimensional features, where each dimension represents the strength of each association type and takes the value between 0 and 1 (the larger the value is, the stronger the association is).
The proteins come from 8 species:  E. coli, A. thaliana, S. cerevisiae, C. elegans, D. melanogaster, D. rerio, H. sapiens, M. musculus. 
Each node comes with an 8-dimensional one-hot feature indicating which species the corresponding protein comes from. 

**Prediction task:** The task is to predict the presence of protein functions (multi-label binary classification). There are 112 kinds of labels to predict in total.

**Dataset splitting:** We split the protein nodes into training/validation/test sets according to species from which the proteins come from.  

**Note:** Details of this dataset will likely change. The dataset is not yet finalized as a benchmark. 

#### References
[1] Szklarczyk, D., Gable, A.L., Lyon, D., Junge, A., Wyder, S., Huerta-Cepas, J., Simonovic, M., Doncheva, N.T., Morris, J.H., Bork, P. and Jensen, L.J., 2018. STRING v11: proteinâ€“protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Nucleic Acids Research, 47(D1), pp.D607-D613. <br/>
[2] Ashburner, M., Ball, C.A., Blake, J.A., Botstein, D., Butler, H., Cherry, J.M., Davis, A.P., Dolinski, K., Dwight, S.S., Eppig, J.T. and Harris, M.A., 2000. Gene ontology: tool for the unification of biology. Nature Genetics, 25(1), p.25.

----------
<a name="ogbn-products"/>
### Dataset `ogbn-products`: ([Leaderboard](../leader_nodeprop/#ogbn-products))

**Graph:** `ogbn-products` is an undirected, unweighted graph, representing an Amazon product co-purchase graph [1]. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. We follow [2] to process node features and target categories. Specifically, node features are generated by extracting bag-of-words features from the product descriptions followed by Principal Component Analysis to reduce the dimension to be 100. 

**Prediction task:** The task is multi-class classification of products into their categories, where top-level 47 categories are used for target labels, and each product is assigned to one of the 47 categories.

**Dataset splitting:** We consider a more challenging and realistic dataset splitting that is different from [2]. First, unlike [2] that uses 90% of nodes for training and 10% of nodes for testing (no validation set is used), we consider a more challenging semi-supervised classification scenario, where only 10% of nodes are labeled, 2% of nodes can be used for validation. The goal is to make predictions on the rest of the 88% nodes.
Furthermore, different from [2] that uses random node splitting, we use the sales ranking (popularity) to split nodes into train/validation/test sets. Specifically, we sort the products according to their sales ranking and use the top 10% for training, next top 2% for validation, and the rest for testing. This respects the real application where labels are first assigned to important nodes in the network, and machine learning is subsequently used to make predictions on less important ones.

**Note:** Details will likely change. The dataset is not yet finalized as a benchmark. 

#### References
[1] http://manikvarma.org/downloads/XC/XMLRepository.html <br/>
[2] Chiang, W. L., Liu, X., Si, S., Li, Y., Bengio, S., & Hsieh, C. J. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. SIGKDD 2019.

----------
<a name="loader"/>

### Data Loader

To load a dataset, replace `d_name` with the dataset name (e.g., `"ogbn-proteins"`).

<a name="pyg"/>

#### Pytorch Geometric Loader

```python
from ogb.nodeproppred.dataset_pyg import PygNodePropPredDataset

dataset = PygNodePropPredDataset(name = d_name) 
num_tasks = dataset.num_tasks # obtaining the number of prediction tasks in a dataset

splitted_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = splitted_idx["train"], splitted_idx["valid"], splitted_idx["test"]
graph = dataset[0] # pyg graph object
```

<a name="dgl"/>

#### DGL Loader

```python
from ogb.nodeproppred.dataset_dgl import DglNodePropPredDataset

dataset = NodePropPredDataset(name = d_name)
num_tasks = dataset.num_tasks # obtaining the number of prediction tasks in a dataset

splitted_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = splitted_idx["train"], splitted_idx["valid"], splitted_idx["test"]
graph, label = dataset[0] # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)
```
`{train,valid,test}_idx` are torch tensors of shape `(num_nodes,)`, representing the node indices assigned to training/validation/test sets.
Prediction target in the Pytorch Geometric dataset can be accessed by `graph.y`, which is a torch tensor of shape `(num_nodes, num_tasks)`, where the i-th row represents the target labels of i-th node.

<a name="libagn"/>

#### Library-Agnostic Loader
```python
from ogb.nodeproppred.dataset import NodePropPredDataset

dataset = NodePropPredDataset(name = d_name)
num_tasks = dataset.num_tasks # obtaining the number of prediction tasks in a dataset

splitted_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = splitted_idx["train"], splitted_idx["valid"], splitted_idx["test"]
graph, label = dataset[0] # graph: library-agnostic graph object
```
The library-agnostic graph object is a dictionary containing the following keys: `edge_index`, `edge_feat`, `node_feat`, and `num_nodes`, which are detailed below.
- `edge_index`: numpy arrays of shape `(2, num_edges)`, where each column represents an edge. The first row and the second row represent the indices of source and target nodes. Undirected edges are represented by bi-directional edges.
- `edge_feat`: numpy arrays of shape `(num_edges, edgefeat_dim)`, where `edgefeat_dim` is the dimensionality of edge features and i-th row represents the feature of i-th edge. This can be `None` if no input edge features are available.
- `node_feat`: numpy arrays of shape `(num_nodes, nodefeat_dim)`, where `nodefeat_dim` is the dimensionality of node features and i-th row represents the feature of i-th node. This can be `None` if no input node features are available.
- `num_nodes`: number of nodes in the graph.

----------
<a name="eval"/>

### Performance Evaluator

Evaluators are customized for each dataset.
We require users to pass a pre-specified format to the evaluator.
First, please learn the input and output format specification of the evaluator as follows.

```python
from ogb.nodeproppred import Evaluator

evaluator = Evaluator(name = d_name)
print(evaluator.expected_input_format) 
print(evaluator.expected_output_format) 
```

Then, you can pass the input dictionary (denoted by `input_dict` below) of the specified format, and get the performance of your prediction.

```python
# In most cases, input_dict is
# input_dict = {"y_true": y_true, "y_pred": y_pred}
result_dict = evaluator.eval(input_dict)
```
