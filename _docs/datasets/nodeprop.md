---
title: Node Property Prediction
permalink: /docs/nodeprop/
---

##### The task is to predict properties of single nodes.

### Summary

#### - Datasets

Scale | Name                              | #Nodes  | #Edges\* | #Tasks | Split Type        | Task Type   | Metric                  |
|:---------:|:--------|----------------:|----------------------:|---------------------:|:-------------------------:|:------------------:|
Medium | [ogbn-products](#ogbn-products) | 2,449,029  | 61,859,140 | 1       | Sales rank      | Multi-class classification | Accuracy |
Small | [ogbn-arxiv](#ogbn-arxiv) | 169,343  | 1,166,243 | 1       | Time      | Multi-class classification | Accuracy |
Medium | [ogbn-proteins](#ogbn-proteins) | 132,534  |  39,561,252 | 112       | Species  | Binary classification   | ROC-AUC     |

**Note:** For undirected graphs, the loaded graphs will have the doubled number of edges because we add the bidirectional edges automatically.

#### - Module
We prepare different [data loader](#loader) variants: (1) [Pytorch Geometric one](#pyg) (2) [DGL one](#dgl) and (3) [library-agnostic one](#libagn).
We also prepare a unified [performance evaluator](#eval).

<a name="ogbn-products"/>

----------

### Dataset `ogbn-products` ([Leaderboard](../leader_nodeprop/#ogbn-products)):

**Graph:** The dataset `ogbn-products` is an undirected and unweighted graph, representing an Amazon product co-purchasing network [1]. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. We follow [2] to process node features and target categories. Specifically, node features are generated by extracting bag-of-words features from the product descriptions followed by a Principal Component Analysis to reduce the dimension to 100.

**Prediction task:** The task is to predict the category of a product in a multi-class classification setup, where the 47 top-level categories are used for target labels.

**Dataset splitting:** We consider a more challenging and realistic dataset splitting that differs from the one used in [2]
Instead of randomly assigning 90% of the nodes for training and 10% of the nodes for testing (without use of a validation set), we use the *sales ranking* (popularity) to split nodes into training/validation/test sets.
Specifically, we sort the products according to their sales ranking and use the top 10% for training, next top 2% for validation, and the rest for testing. This is a more challenging splitting procedure that closely matches the real-world application where labels are first assigned to important nodes in the network and ML models are subsequently used to make predictions on less important ones.

#### References
[1] [http://manikvarma.org/downloads/XC/XMLRepository.html](http://manikvarma.org/downloads/XC/XMLRepository.html) <br/>
[2] Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 257–266, 2019.

<a name="ogbn-arxiv"/>

----------

### Dataset `ogbn-arxiv` ([Leaderboard](../leader_nodeprop/#ogbn-arxiv)):

**Graph:** 
The dataset `ogbn-arxiv` is a directed graph, representing the citation network between all Computer Science (CS) arXiv papers indexed by MAG [1]. Each node is an arXiv paper and each directed edge indicates that one paper cites another one. 
Each paper comes with a 128-dimensional feature vector obtained by averaging the embeddings of words in its title and abstract. 
The embeddings of individual words are computed by running the skip-gram model [2] over the MAG corpus. 
In addition, all papers are also associated with the year that the corresponding paper was published. 

**Prediction task:** The task is to predict the 40 subject areas of arXiv CS papers, e.g., cs.AI, cs.LG, and cs.OS, which are manually determined (i.e., labeled) by the paper's authors and arXiv moderators. 
With the volume of scientific publications doubling every 12 years over the past century, it is practically critical to automatically classify each publication's areas and topics. 
Formally, this prediction task is formulated as a 40-class classification problem.

**Dataset splitting:** We consider a realistic data split based on the publication dates of the papers. 
The general setting is that the ML models are trained on existing papers and then used to predict the subject areas of newly-published papers, which supports the direct application of them into real-world scenarios, such as replacing the arXiv moderators. 
Specifically, we propose to train on papers published until 2017, validate on those published in 2018, and test on those published in 2019.

#### References
[1] Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia.Microsoft academic graph:  When experts are not enough. Quantitative Science Studies, 1(1):396–413, 2020. <br/>
[2] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representationsof words and phrases and their compositionality. In Advances in Neural Information Processing Systems (NeurIPS), pp. 3111–3119, 2013.


<a name="ogbn-proteins"/>

------

### Dataset `ogbn-proteins` ([Leaderboard](../leader_nodeprop/#ogbn-proteins)):

**Graph:** The dataset `ogbn-proteins` is an undirected, weighted, and typed (according to species) graph. Nodes represent proteins, and edges indicate different types of biologically meaningful associations between proteins, e.g., physical interactions, co-expression or homology [1,2]. All edges come with 8-dimensional features, where each dimension represents the strength of a single association type and takes values between 0 and 1 (the larger the value is, the stronger the association is). The proteins come from 8 species.

**Prediction task:** The task is to predict the presence of protein functions in a multi-label binary classification setup, where there are 112 kinds of labels to predict in total. The performance is measured by the average of ROC-AUC scores across the 112 tasks.

**Dataset splitting:** We split the protein nodes into training/validation/test sets according to the species which the proteins come from. This enables the evaluation of the generalization performance of the model *across* different species.


#### References
[1] Damian Szklarczyk, Annika L Gable, David Lyon, Alexander Junge, Stefan Wyder, Jaime Huerta- Cepas, Milan Simonovic, Nadezhda T Doncheva, John H Morris, Peer Bork, et al. STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Nucleic Acids Research, 47(D1):D607–D613, 2019. <br/>
[2] Gene Ontology Consortium. The gene ontology resource: 20 years and still going strong. Nucleic Acids Research, 47(D1):D330–D338, 2018.


<a name="loader"/>

----------

### Data Loader

To load a dataset, replace `d_name` with the dataset name (e.g., `"ogbn-proteins"`).

<a name="pyg"/>

#### Pytorch Geometric Loader

```python
from ogb.nodeproppred import PygNodePropPredDataset

dataset = PygNodePropPredDataset(name = d_name) 

split_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = split_idx["train"], split_idx["valid"], split_idx["test"]
graph = dataset[0] # pyg graph object
```

<a name="dgl"/>

#### DGL Loader

```python
from ogb.nodeproppred import DglNodePropPredDataset

dataset = DglNodePropPredDataset(name = d_name)

split_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = split_idx["train"], split_idx["valid"], split_idx["test"]
graph, label = dataset[0] # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)
```
`{train,valid,test}_idx` are torch tensors of shape `(num_nodes,)`, representing the node indices assigned to training/validation/test sets.
Prediction target in the Pytorch Geometric dataset can be accessed by `graph.y`, which is a torch tensor of shape `(num_nodes, num_tasks)`, where the i-th row represents the target labels of i-th node.

<a name="libagn"/>

#### Library-Agnostic Loader
```python
from ogb.nodeproppred import NodePropPredDataset

dataset = NodePropPredDataset(name = d_name)

split_idx = dataset.get_idx_split()
train_idx, valid_idx, test_idx = split_idx["train"], split_idx["valid"], split_idx["test"]
graph, label = dataset[0] # graph: library-agnostic graph object
```
The library-agnostic graph object is a dictionary containing the following keys: `edge_index`, `edge_feat`, `node_feat`, and `num_nodes`, which are detailed below.
- `edge_index`: numpy arrays of shape `(2, num_edges)`, where each column represents an edge. The first row and the second row represent the indices of source and target nodes. Undirected edges are represented by bi-directional edges.
- `edge_feat`: numpy arrays of shape `(num_edges, edgefeat_dim)`, where `edgefeat_dim` is the dimensionality of edge features and i-th row represents the feature of i-th edge. This can be `None` if no input edge features are available.
- `node_feat`: numpy arrays of shape `(num_nodes, nodefeat_dim)`, where `nodefeat_dim` is the dimensionality of node features and i-th row represents the feature of i-th node. This can be `None` if no input node features are available.
- `num_nodes`: number of nodes in the graph.

**Node:** Some graph datasets may contain additional meta-information in node or edges such as their time stamps. Although they are not given as default input features, researchers should feel free to exploit these additional information.

<a name="eval"/>

----------


### Performance Evaluator

Evaluators are customized for each dataset.
We require users to pass a pre-specified format to the evaluator.
First, please learn the input and output format specification of the evaluator as follows.

```python
from ogb.nodeproppred import Evaluator

evaluator = Evaluator(name = d_name)
print(evaluator.expected_input_format) 
print(evaluator.expected_output_format) 
```

Then, you can pass the input dictionary (denoted by `input_dict` below) of the specified format, and get the performance of your prediction.

```python
# In most cases, input_dict is
# input_dict = {"y_true": y_true, "y_pred": y_pred}
result_dict = evaluator.eval(input_dict)
```
