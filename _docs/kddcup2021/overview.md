---
title: OGB-LSC @ KDD Cup 2021
permalink: /kddcup2021/
layout: kdd_overview
---

#### **Why a Large-Scale Graph ML Competiton?**
Machine Learning (ML) on graphs has attracted immense attention in recent years because of the prevalence of graph-structured data in real-world applications. 
Modern application domains include web-scale social networks, recommender systems, hyperlinked web documents, knowledge graphs (KGs), as well as 
molecule simulation data generated by the ever-increasing scientific computation. These domains involve large-scale graphs with billions of edges or a dataset with millions of graphs.
Deploying accurate graph ML at scale will have a huge practical impact, enabling better recommendation results, improved web document search, more comprehensive KGs, and accurate ML-based drug and material discovery.
However, community efforts to advance state-of-the-art in large-scale graph ML have been extremely limited.
In fact, most of graph ML models have been developed and evaluated on extremely small datasets. 

Handling large-scale graphs is challenging, especially for state-of-the-art expressive Graph Neural Networks (GNNs) because they make prediction on each node based on the information from many other nodes. Effectively training these models at scale requires sophisticated algorithms that are well beyond standard SGD over i.i.d. data. 
More recently, researchers improve model scalability by significantly simplifying GNNs, which inevitably limits their expressive power.
 
However, in deep learning, it has been demonstrated over and over again that one needs big expressive models and train them on big data to achieve the best performance. In graph ML, the trend has been the opposite---models get simplified and less expressive to be able to scale to large graphs. Thus, there is a massive opportunity to move the community to work with realistic and large-scale graph datasets and move the state of the field forward to where it needs to be.

------------

#### **Overview of OGB-LSC**

Here we propose a large-scale graph ML competition, **OGB Large-Scale Challenge (OGB-LSC)**, to encourage the development of state-of-the-art graph ML models for massive modern datasets. 
Specifically, **we present three datasets: [MAG240M-LSC](mag240m/)**, **[WikiKG90M-LSC](wikikg90m/)**, and **[PCQM4M-LSC](pcqm4m/)**, that are unprecedentedly large in scale and cover prediction at the level of nodes, links, and graphs, respectively.
**Each dataset offers an independent task, and the winners will be selected separately for each dataset.**
We will announce the top 3 winning teams for each of the datasets (in total of 9 winning teams), and they will be given opportunities to present their solutions during the KDD Cup workshop.

An illustrative overview of the three OGB-LSC datasets is provided below.
<p align = "center">
<img width="90%" src="{{ "/assets/img/ogb-lsc-task-overview.png" | relative_url }}" class="img-responsive">
</p>
- **[MAG240M-LSC](mag240m/)** is a heterogeneous academic graph, and the task is to predict the subject areas of papers situated in the heterogeneous graph (node classification). 
- **[WikiKG90M-LSC](wikikg90m/)** is a knowledge graph, and the task is to impute missing triplets (link prediction). 
- **[PCQM4M-LSC](pcqm4m/)** is a quantum chemistry dataset, and the task is to predict an important molecular property, the HOMO-LUMO gap, of a given molecule (graph regression).

For each dataset, we carefully design its prediction task and data split so that achieving high prediction performance on the task will have direct impact on the corresponding application. Further details are provided in each dataset page.

The dataset statistics as well as basic information are summarized below, showing that our datasets are extremely large.

Task category | Name      | Package      |  #Graphs      | #Total nodes  | #Total edges  | Data split        | Task Type   | Metric  | Download size
|:---------:|:--------|-----:|-----:|----------------:|----------------------:|:---------------|:-------|:---------|---------:|
Node-level | **[MAG240M-LSC](mag240m/)** | >=1.3.0 | 1 | 244,160,499  | 1,728,364,232 | Time      | Multi-class classification | Accuracy | 168GB |
Link-level | **[WikiKG90M-LSC](wikikg90m/)** |  >=1.3.0  | 1 | 87,143,637 | 504,220,369 |  Time    | KG completion | MRR | 94GB
Graph-level | **[PCQM4M-LSC](pcqm4m/)** |  >=1.3.0  | 3,803,453  | 53,814,542 | 55,399,880   | Scaffold      | Regression | MAE | 58MB**\*** 

**\***: The PCQM4M-LSC dataset is provided in the SMILES strings. After processing them into graph objects, the eventual file size will be around 8GB.

**All of these datasets can be downloaded and prepared using our [`ogb` Python package](https://github.com/snap-stanford/ogb).**
**The model evaluation and test submission file preparation are also handled by our package.**
The usage is described in each dataset page. Please install/update it by:
```bash
pip install -U ogb
# Make sure below prints the required package version for the dataset you are working on.
python -c "import ogb; print(ogb.__version__)"
```

In our **[paper](http://arxiv.org/abs/2103.09430)**, we further perform an extensive baseline analysis on each dataset, implementing simple baseline models as well as advanced expressive models at scale.
We find that advanced expressive models, despite requiring more efforts to scale up, do benefit from large data and significantly outperform simple baseline models that are easy to scale.
All of our baseline code is made **[publicly available](https://github.com/snap-stanford/ogb/tree/master/examples/lsc)** to facilitate public research.

Overall, our KDD Cup will encourage the community to develop and scale up expressive graph ML models, which can yield significant breakthroughs in the respective domains. 
We hope OGB-LSC at KDD Cup 2021 will serve as an "ImageNet Large Scale Visual Recognition Challenge" in the field of graph ML, encouraging the community to work on realistic and large-scale graph datasets and significantly advance the state-of-the-art.

-----------

#### **[Paper](http://arxiv.org/abs/2103.09430)**

Details about our datasets and our initial baseline analysis are described in our **[OGB-LSC paper](http://arxiv.org/abs/2103.09430)**.
If you use OGB-LSC in your work, please cite our paper (Bibtex below)

```
@article{hu2021ogblsc,
  title={OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs},
  author={Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, Jure Leskovec},
  journal={arXiv preprint arXiv:2103.09430},
  year={2021}
}
```


--------

#### **OGB-LSC Team and Contact**

The OGB-LSC team can be reached at **<ogb-lsc@cs.stanford.edu>**. 
For discussion or general questions about the datasets, use **[our Github discussion](https://github.com/snap-stanford/ogb/discussions)**.
For questions about our code, use **[our Github issues](https://github.com/snap-stanford/ogb/issues)**. Subscribe to **[our Google group](https://groups.google.com/forum/#!forum/open-graph-benchmark)** to keep yourself updated with any changes and updates from us.

We greatly acknowledge **[Adrijan Bradaschia](https://www.linkedin.com/in/adrijan-bradaschia-7b58ba8a/)** (Stanford) for setting up the server and the test submission page.
We also sincerely acknowledge the [DGL Team](https://www.dgl.ai/) for help hosting our data on AWS, which allows much faster downloading.

<table style="background-color:#FDFEFE; border:none;">
  <tr>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/weihua.png" | relative_url }}" class="img-responsive">
      <strong><a href="http://web.stanford.edu/~weihuahu/">Weihua Hu</a></strong> <br/> Stanford University
      </div>
    </td>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/matthias.png" | relative_url }}" class="img-responsive">
      <strong><a href="https://rusty1s.github.io/#/">Matthias Fey</a></strong> <br/> TU Dortmund
      </div>
    </td>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/hongyu.png" | relative_url }}" class="img-responsive">
      <strong><a href="http://hyren.me/">Hongyu Ren</a></strong> <br/> Stanford University
      </div>
    </td>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/maho.png" | relative_url }}" class="img-responsive">
      <strong><a href="http://nakatamaho.riken.jp/">Maho Nakata</a></strong> <br/> RIKEN
      </div>
    </td>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/yuxiao.png" | relative_url }}" class="img-responsive">
      <strong><a href="https://ericdongyx.github.io/">Yuxiao Dong</a></strong> <br/> Facebook AI
      </div>
    </td>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/jure.png" | relative_url }}" class="img-responsive">
      <strong><a href="https://cs.stanford.edu/people/jure/">Jure Leskovec</a></strong> <br/> Stanford University
      </div>
    </td>
  </tr> 
</table>

#### **Partners**
<table style="background-color:#FDFEFE; border:none;">
  <tr>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/amit.png" | relative_url }}" class="img-responsive">
      <strong>Amit Bleiweiss</strong> <br/> Intel
      </div>
    </td>
    <td>
    <div style="margin: 0 auto; width: 150px; text-align: center">
      <img src="{{ "/assets/img/portrait/benjamin.png" | relative_url }}" class="img-responsive">
      <strong>Benjamin Braun</strong> <br/> Intel
      </div>
    </td>
  </tr> 
</table>
